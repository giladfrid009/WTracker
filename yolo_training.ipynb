{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "from utils.gui_utils import UserPrompt\n",
    "from utils.path_utils import join_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "dataset_folder = \"data/yolo/CElegan-Head-5\"\n",
    "config_file = \"data/yolo/yolo_train_config.yaml\"\n",
    "dataset_file = join_paths(dataset_folder, \"data.yaml\")\n",
    "\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Roboflow is used, copy the code produced by Roboflow to the cell below and run it to download the dataset.   \n",
    "Otherwise, if the dataset is already on the system there is no need to do this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "################################ User Input ################################\n",
    "\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"technion-institute-of-technology\").project(\"celegan-head\")\n",
    "version = project.version(5)\n",
    "\n",
    "\n",
    "\n",
    "dataset = version.download(\"yolov8\", location=dataset_folder, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load a base model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "# can be one of the models stated at the ultraliytics documentation or a \n",
    "# path to a trained model on the disk\n",
    "model_path = \"yolov8s\"  \n",
    "\n",
    "############################################################################\n",
    "\n",
    "if model_path is None:\n",
    "    yolo_model_path = UserPrompt.open_file(\"Select YOLO model\", (\"pytorch file\", \"*.pt\"))\n",
    "\n",
    "model = YOLO(model=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data=dataset_file, cfg=config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to faster format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model=model_path)\n",
    "\n",
    "out = model.export(\n",
    "    format=\"engine\",  # Use 'engine' for TensorRT (GPU), 'onnx' for ONNX (CPU/GPU).\n",
    "    imgsz=384,\n",
    "    half=False,  # Enables FP16 (half-precision) quantization, reducing model size and potentially speeding up inference on supported hardware.\n",
    "    dynamic=False,  # Allows dynamic input sizes for ONNX and TensorRT exports, enhancing flexibility in handling varying image dimensions\n",
    "    simplify=False,  # Simplifies the model graph for ONNX exports, potentially improving performance and compatibility\n",
    "    verbose=False,\n",
    "    batch=8,  # max supported batch size of the exported model\n",
    "    workspace=8,  # max memory usage during the export process in GB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy Model to Roboflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

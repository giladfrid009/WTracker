{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from evaluation.vlc import VLC\n",
    "\n",
    "from evaluation.vlc import VLC\n",
    "from utils.path_utils import Files\n",
    "from evaluation.simulator import TimingConfig\n",
    "from evaluation.analysis import Plotter\n",
    "\n",
    "from neural.dataset import Dataset, numpyDataset\n",
    "from neural.mlp import MLP\n",
    "from neural.training import Trainer, MLPTrainer\n",
    "from neural.train_results import FitResult\n",
    "\n",
    "%matplotlib qt\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_X_path = \"/Users/guycohen/Desktop/Bio-Project/dataset/dataset_X.npy\"\n",
    "dataset_y_path = \"/Users/guycohen/Desktop/Bio-Project/dataset/dataset_y.npy\"\n",
    "\n",
    "# dataset_X = pd.read_csv(dataset_X_path).to_numpy(dtype=np.float32, copy=True)\n",
    "# dataset_y = pd.read_csv(dataset_y_path).to_numpy(dtype=np.float32)\n",
    "\n",
    "dataset_X = np.load(dataset_X_path, allow_pickle=True)\n",
    "dataset_y = np.load(dataset_y_path, allow_pickle=True)\n",
    "\n",
    "\n",
    "dataset = numpyDataset(dataset_X, dataset_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "ds_train, ds_test = torch.utils.data.random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0424, 8.3700],\n",
       "        [4.1868, 8.3296],\n",
       "        [3.9232, 8.6399],\n",
       "        [3.7290, 8.8073],\n",
       "        [3.6161, 8.7173],\n",
       "        [3.7101, 8.5582],\n",
       "        [3.7382, 8.7291],\n",
       "        [3.6084, 9.0193],\n",
       "        [3.4424, 9.2344],\n",
       "        [3.2963, 9.4738]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.set_printoptions(suppress=True)\n",
    "\n",
    "ds_train.dataset[:10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [120, 40, 12, 4, 2]\n",
    "activaations = ['relu'] * (len(hidden_dims))# + ['softmax']\n",
    "in_dim = ds_train[0][0].shape[0]\n",
    "model = MLP(in_dim=in_dim, dims=hidden_dims, nonlins=activaations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (sequence): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=10, out_features=60, bias=True)\n",
      "    (4): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=60, out_features=40, bias=True)\n",
      "    (7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=40, out_features=12, bias=True)\n",
      "    (10): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=12, out_features=4, bias=True)\n",
      "    (13): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (16): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MLPTrainer(model, loss_fn, optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 1/1000 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa430f64dbf4d0bbbdf83f56ca67a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d6b89273749b9b5d9fb522b1e5ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_batch:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saved checkpoint mlpRELU :: val_loss=1.390\n",
      "\n",
      "*** Saved checkpoint mlpRELU :: val_loss=1.250\n",
      "--- EPOCH 6/1000 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c34ce3b1e444698a9e161b440572fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b444c81464fcd991cdd80ad845d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_batch:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 11/1000 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1f90c03f44466cb6780c36d2849b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f5e47ffce849ebbd534cb80da53d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_batch:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saved checkpoint mlpRELU :: val_loss=1.188\n",
      "--- EPOCH 16/1000 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785ea69419d2451eab089abb73824976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9053dc7d46744171976368b5306956c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_batch:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 21/1000 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83c95898b304fdcaf2b390967fcaf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_batch:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbbc340709a43098d31164f1cb9b123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_batch:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlpRELU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Bio-Project/Bio-Proj/neural/training.py:98\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, dl_train, dl_test, num_epochs, checkpoints, early_stopping, print_every, **kw)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose)\n\u001b[1;32m     97\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch(dl_train, verbose\u001b[38;5;241m=\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m---> 98\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mextend(train_result\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[1;32m    101\u001b[0m train_acc\u001b[38;5;241m.\u001b[39mappend(train_result\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/Desktop/Bio-Project/Bio-Proj/neural/training.py:146\u001b[0m, in \u001b[0;36mTrainer.test_epoch\u001b[0;34m(self, dl_test, **kw)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mEvaluate model once over a test set (single epoch).\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m:param dl_test: DataLoader for the test set.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m:param kw: Keyword args supported by _foreach_batch.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m:return: An EpochResult for the epoch.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# set evaluation (test) mode\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Bio-Project/Bio-Proj/neural/training.py:212\u001b[0m, in \u001b[0;36mTrainer._foreach_batch\u001b[0;34m(dl, forward_fn, verbose, max_batches)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    211\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dl_iter)\n\u001b[0;32m--> 212\u001b[0m     batch_res \u001b[38;5;241m=\u001b[39m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpbar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_res\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/mambaforge/envs/bio-projML/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Bio-Project/Bio-Proj/neural/training.py:262\u001b[0m, in \u001b[0;36mMLPTrainer.test_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    260\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 262\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# preds = torch.argmax(probs, dim=1)\u001b[39;00m\n\u001b[1;32m    264\u001b[0m num_correct \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((preds \u001b[38;5;241m-\u001b[39m y)\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Bio-Project/Bio-Proj/neural/mlp.py:72\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    :param x: An input tensor, of shape (N, D) containing N samples with D features.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :return: An output tensor of shape (N, D_out) where D_out is the output dim.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bio-projML/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(dl_train=dl_train, dl_test=dl_test, num_epochs=1000, checkpoints='mlpRELU', print_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_config = TimingConfig.load_json(\"/Users/guycohen/Desktop/Bio-Project/time_config.json\")\n",
    "\n",
    "log_path = \"/Users/guycohen/Desktop/Bio-Project/eval/bboxes2.csv\"\n",
    "\n",
    "\n",
    "pltr = Plotter(log_path, timing_config)\n",
    "data = pltr._data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(8), columns=['x', 'y'])\n",
    "df.iloc[0]  = [1, 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[0,-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.ag\n",
    "data.rolling(window=10, method='table').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40).reshape(8,5)[[2,3]].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.dropna(inplace=False, ignore_index=False, axis=0)\n",
    "mask = data.isna().any(axis=1)\n",
    "data['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that 0 is first at frames_for_pred\n",
    "def create_dataset(log_path: str, frames_for_pred=[0,-3,-15], pred_frame=7, save_path:str=None) -> Dataset:\n",
    "    data = pd.read_csv(log_path)\n",
    "    start_idx = abs(min(frames_for_pred)) + 1\n",
    "    X_mask = np.asanyarray(frames_for_pred)\n",
    "    y_mask = np.asanyarray([pred_frame])\n",
    "\n",
    "    data = Plotter.concat(data, Plotter.calc_centers(data, \"wrm\"))\n",
    "    \n",
    "    wrm_centers = data[['wrm_center_x', 'wrm_center_y']].to_numpy(dtype=np.float64)\n",
    "    wrm_boxes = data[['wrm_x', 'wrm_y', 'wrm_w', 'wrm_h']].to_numpy(dtype=np.float64)\n",
    "    \n",
    "    # Create columns for X and y\n",
    "    cols = ['wrm_x', 'wrm_y', 'wrm_w', 'wrm_h']\n",
    "    y_cols = ['wrm_center_x', 'wrm_center_y']\n",
    "    X_cols = []\n",
    "    for i in frames_for_pred:\n",
    "        X_cols += [col+str(i) for col in cols]\n",
    "    \n",
    "    # Create X and y\n",
    "    X = pd.DataFrame(index=data.index, columns=X_cols)\n",
    "    y = pd.DataFrame(index=data.index, columns=y_cols)\n",
    "    for i in range(start_idx, len(data)-pred_frame-1):\n",
    "        X.iloc[i] = wrm_boxes[i + X_mask].reshape(1, -1)\n",
    "        y.iloc[i] = wrm_centers[i + y_mask].reshape(1, -1)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    na_mask = np.ma.mask_or(X.isna().any(axis=1), y.isna().any(axis=1))\n",
    "    X = X.loc[~na_mask]\n",
    "    y = y.loc[~na_mask]\n",
    "    \n",
    "    X = X.to_numpy(dtype=np.float32, copy=True)\n",
    "    y = y.to_numpy(dtype=np.float32, copy=True)\n",
    "\n",
    "    # make X and y coordinates relative to the prediction frame\n",
    "    x_cord_mask = np.arange(X.shape[1]) % 4 == 0\n",
    "    y_cord_mask = np.arange(X.shape[1]) % 4 == 1\n",
    "    \n",
    "    x_cords = X[:, 0].reshape(-1, 1)\n",
    "    y_cords = X[:, 1].reshape(-1, 1)\n",
    "\n",
    "    y[:, [0]] -= x_cords\n",
    "    y[:, [1]] -= y_cords\n",
    "    X[:, x_cord_mask] -= x_cords#\n",
    "    X[:, y_cord_mask] -= y_cords#.reshape(-1, 1)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        np.save(save_path + \"dataset_X_3.npy\", X, allow_pickle=True)\n",
    "        np.save(save_path + \"dataset_y_3.npy\", y, allow_pickle=True)\n",
    "        # X.to_csv(save_path + \"dataset_X.csv\", index=False)\n",
    "        # y.to_csv(save_path + \"dataset_y.csv\", index=False)\n",
    "\n",
    "    return numpyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"/Users/guycohen/Desktop/Bio-Project/eval/bboxes2.csv\"\n",
    "\n",
    "pred_frame=3\n",
    "frames_for_pred=[0,-3,-15,-18,-30]\n",
    "ds = create_dataset(log_path, save_path=\"/Users/guycohen/Desktop/Bio-Project/dataset/\", frames_for_pred=frames_for_pred, pred_frame=pred_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ds[:]\n",
    "df = pd.DataFrame({\"dx\": y[:,0], \"dy\": y[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

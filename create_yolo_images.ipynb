{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Dataset Image Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of this notebook is to create images for the YOLO dataset.\n",
    "The YOLO model is the model that is used to predict a bounding box around worm's head.\n",
    "In order for the model to make successful detections, the model must be trained on example images.\n",
    "In this notebook, we create such example images. As input, we expect images containing the entire arena, and the resulting output images are images of some *pre-defined fixed* size, in which the worm is visible.\n",
    "These output images are obtained by cropping the input images around the worm which was detected within it. Each such cropped image is referred to as sample.\n",
    "It's important to note, that we create as many samples as we would like, and we do not have to extract a sample image from every input image. \n",
    "\n",
    "The proper function of this notebook relies on the following assumptions, and would not function correctly if they do not hold:\n",
    "1.  In the original footage of the experiment, the background is stationary and always within the field of view. \n",
    "    That is, the position of the camera that captured the experiment footage is constant with regards to the arena.\n",
    "2.  At each frame, a single instance of the worm is visible, no less and no more.\n",
    "\n",
    "To detect the worm positions within the input images, the following process is performed:\n",
    "1.  The background is calculated by sampling large amount of raw input images, and calculating pixelwise median among them.\n",
    "2.  Given some input image, non-background objects are calculated by subtracting the background from the image, and marking the regions where the difference is greater than some pre-defined threshold.\n",
    "3.  Among non-background objects detected in the input image, the biggest object is found and treated as the worm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from utils.frame_reader import *\n",
    "from dataset.box_calculator import *\n",
    "from dataset.sample_extractor import *\n",
    "from utils.gui_utils import UserPrompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "# select the folder containing the original frame images \n",
    "src_folder = None\n",
    "\n",
    "# select the folder into which the extracted samples will be saved to\n",
    "output_folder = None\n",
    "\n",
    "############################################################################\n",
    "\n",
    "if src_folder is None:\n",
    "    src_folder = UserPrompt.open_directory(\"Select the folder containing the original frame images\")\n",
    "\n",
    "if output_folder is None:\n",
    "    output_folder = UserPrompt.open_directory(\"Select the folder into which the extracted samples will be saved to\")\n",
    "\n",
    "print(f\"original frame images folder: {src_folder}\")\n",
    "print(f\"output folder: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all files from the source folder\n",
    "src_frames = FrameReader.create_from_directory(src_folder, read_format=cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreground object detection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "# define the parameters by which objects are detected\n",
    "\n",
    "box_calc = BoxCalculator(\n",
    "    bg_probes=1000,  # number of images to use to calculate the background\n",
    "    diff_thresh=10,  # threshold for the difference between the background and the current frame to detect non-background objects\n",
    "    frame_reader=src_frames,\n",
    ")\n",
    "\n",
    "############################################################################\n",
    "\n",
    "# create sample extractor which uses the BoxCalculator to extract samples\n",
    "sample_extractor = SampleExtractor(box_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of samples from the input images\n",
    "\n",
    "Note, that the following step might take a while, especially if the count of extracted samples is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "# extract samples from the original images\n",
    "\n",
    "sample_extractor.create_samples(\n",
    "    count=300,  # number of samples to extract\n",
    "    target_size=(384, 384),  # size of the extracted samples\n",
    "    name_format=\"img_{:09d}.png\",  # naming format of the extracted samples\n",
    "    num_workers=None,  # multiprocessing related, read doc for more info\n",
    "    chunk_size=50,  # multiprocessing related, read doc for more info\n",
    "    save_folder=output_folder,\n",
    ")\n",
    "\n",
    "############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is used to create and train a neural network model for the purpose of predicting the worm movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tkfilebrowser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Files\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_initialization\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetConfig, TrainConfig, IOConfig, LOSSES, OPTIMIZERS\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyDataset\n",
      "File \u001b[1;32md:\\Guy_Gilad\\Bio-Proj\\wtracker\\utils\\config_base.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass, fields, MISSING, is_dataclass\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgui_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserPrompt\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_load_object, pickle_save_object\n\u001b[0;32m      9\u001b[0m T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigBase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Guy_Gilad\\Bio-Proj\\wtracker\\utils\\gui_utils.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkfilebrowser\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFocusedWindow\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tkfilebrowser'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from wtracker.utils.path_utils import Files\n",
    "from wtracker.utils.config_base import print_initialization\n",
    "from wtracker.neural.config import DatasetConfig, TrainConfig, IOConfig, LOSSES, OPTIMIZERS\n",
    "from wtracker.neural.dataset import NumpyDataset\n",
    "from wtracker.neural.mlp import MlpBlock, RMLP, WormPredictor\n",
    "from wtracker.neural.training import MLPTrainer\n",
    "from wtracker.neural.train_results import FitResult\n",
    "from wtracker.utils.gui_utils import UserPrompt\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Model, Dataset and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "# path to the log file, used to train the network\n",
    "# if None, a file dialog will open to select the file\n",
    "log_path = None \n",
    "\n",
    "io_config = IOConfig(\n",
    "    input_frames=[0, -3, -15, -18, -30],  # list\n",
    "    pred_frames=[12],  # list\n",
    ")\n",
    "\n",
    "############################################################################\n",
    "\n",
    "if log_path is None:\n",
    "    log_path = UserPrompt.open_file(\"Please select the log file to use for training\")\n",
    "\n",
    "dataset_config = DatasetConfig.from_io_config(io_config, log_path) # create a dataset config object from the io_config and log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network model based on the dataset_config. Will be ignored if a model path is given by TrainConfig\n",
    "block_in_dim = 40\n",
    "block_dims = [10, 4, 10, 40]\n",
    "block_activations = [\"relu\"] * (len(block_dims))\n",
    "in_dim = 4 * len(dataset_config.input_frames)\n",
    "out_dim = 2 * len(dataset_config.pred_frames)\n",
    "\n",
    "model = RMLP(\n",
    "    in_dim=in_dim,\n",
    "    block_in_dim=block_in_dim,\n",
    "    block_dims=block_dims,\n",
    "    block_nonlins=block_activations,\n",
    "    n_blocks=4,\n",
    "    out_dim=out_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we wrap the model in a WormPredictor object, which will hold the io_config for future use and distinguish it from general Neural Network models.\n",
    "model = WormPredictor(model, io_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model) # print the model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ User Input ################################\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    seed=42,  # int\n",
    "    dataset=dataset_config,  # Dataset\n",
    "    model=model,  # Union[nn.Module, str]\n",
    "    loss_fn=\"mse\",  # nn.Module\n",
    "    optimizer=\"adam\",  # Union[Optimizer, str]\n",
    "    device=f\"cpu\",  # str\n",
    "    log=True,  # bool\n",
    "    num_epochs=100,  # int\n",
    "    checkpoints=\"RMLP4\",  # str\n",
    "    early_stopping=15,  # int\n",
    "    print_every=5,  # int\n",
    "    learning_rate=0.001,  # float\n",
    "    weight_decay=1e-05,  # float\n",
    "    batch_size=256,  # int\n",
    "    shuffle=True,  # bool\n",
    "    num_workers=0,  # int\n",
    "    train_test_split=0.8,  # float\n",
    ")\n",
    "\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run The Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset according to the dataset_config\n",
    "dataset = NumpyDataset.create_from_config(dataset_config, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "ds_train, ds_test = random_split(dataset, [train_config.train_test_split, 1 - train_config.train_test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "dl_train = DataLoader(ds_train, batch_size=train_config.batch_size, shuffle=train_config.shuffle)\n",
    "dl_test = DataLoader(ds_test, batch_size=train_config.batch_size, shuffle=train_config.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the loss object\n",
    "loss_fn = LOSSES[train_config.loss_fn]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer object\n",
    "lr = train_config.learning_rate\n",
    "weight_decay = train_config.weight_decay\n",
    "optimizer = OPTIMIZERS[train_config.optimizer](model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trainer object\n",
    "device = torch.device(train_config.device)\n",
    "trainer = MLPTrainer(model, loss_fn, optimizer, device=device, log=train_config.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = train_config.num_epochs\n",
    "checkpoints = train_config.checkpoints\n",
    "early_stopping = train_config.early_stopping\n",
    "print_every = train_config.print_every\n",
    "\n",
    "trainer.fit(\n",
    "    dl_train=dl_train,\n",
    "    dl_test=dl_test,\n",
    "    num_epochs=epochs,\n",
    "    checkpoints=checkpoints,\n",
    "    print_every=print_every,\n",
    "    early_stopping=early_stopping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training configuration if logging is enabled\n",
    "if train_config.log:\n",
    "    train_config.save_pickle(trainer.logger.log_dir + \"/train_config.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

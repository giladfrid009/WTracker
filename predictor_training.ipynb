{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.path_utils import Files\n",
    "from neural.config import *\n",
    "from evaluation.analysis import Plotter\n",
    "\n",
    "from neural.dataset import numpyDataset\n",
    "from neural.mlp import MLP, MlpBlock, RMLP\n",
    "from neural.training import Trainer, MLPTrainer\n",
    "from neural.train_results import FitResult\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"MLP\"\n",
    "params = {'in_dim': 2,\n",
    " 'dims': [3],\n",
    " 'nonlins': ['none']\n",
    " }\n",
    "MLP.__init__.__annotations__\n",
    "globals()[class_name](**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MlpBlock(2, [3,4,5], ['relu']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig(\n",
    "    input_frames = [0,-3,-15,-18,-30], # list\n",
    "    pred_frames = [12], # list\n",
    "    log_path = './data/Data/Exp1_GuyGilad_logs_yolo/bboxes.csv', # str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(\n",
    "    seed = 42, # int\n",
    "    dataset = None, # Dataset\n",
    "    model = None, # Module\n",
    "    loss_fn = None, # Union\n",
    "    optimizer = None, # Union\n",
    "    device = f\"cuda\", # str\n",
    "    num_epochs = 100, # int\n",
    "    checkpoints = None, # str\n",
    "    early_stopping = (None,), # int\n",
    "    print_every = (5,), # int\n",
    "    learning_rate = 0.001, # float\n",
    "    weight_decay = 1e-05, # float\n",
    "    batch_size = 64, # int\n",
    "    shuffle = True, # bool\n",
    "    num_workers = 0, # int\n",
    "    train_test_split = 0.8, # float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpyDataset.create_from_config(dataset_config, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.0000,   0.0000,   8.7995,  18.8014,  -0.6705,  -1.5002,  10.7784,  17.0660,  -4.8260,  -3.7474,  13.1253,  15.0996,  -6.3208,  -4.5732,  14.2787,  14.4549, -12.2964,  -5.4672,  18.1100,   9.3417],\n",
       "         [  0.0000,   0.0000,   8.2723,  19.6013,  -0.7405,  -1.2722,  10.3475,  17.5733,  -4.6796,  -3.7275,  12.8785,  15.4929,  -6.0377,  -4.2960,  14.1505,  14.3362, -11.9426,  -5.5149,  17.7434,   9.8989],\n",
       "         [  0.0000,   0.0000,   7.6832,  18.8124,  -0.8237,  -1.2946,   9.5970,  18.0676,  -4.7349,  -4.3338,  12.6514,  15.5564,  -5.8790,  -4.7156,  13.8074,  14.5691, -11.8043,  -6.3584,  17.2552,  10.5552],\n",
       "         [  0.0000,   0.0000,   7.3536,  18.5492,  -0.8936,  -1.2064,   8.7995,  18.8014,  -4.5927,  -4.8354,  12.4866,  15.6268,  -5.7196,  -4.9539,  13.1253,  15.0996, -11.6421,  -6.9247,  17.0589,  11.0077],\n",
       "         [  0.0000,   0.0000,   7.2080,  18.6316,  -0.8080,  -1.9869,   8.2723,  19.6013,  -4.5179,  -5.3358,  12.5956,  15.5478,  -5.4875,  -5.7145,  12.8785,  15.4929, -11.3107,  -7.5658,  16.4763,  11.6894],\n",
       "         [  0.0000,   0.0000,   7.6321,  18.6367,  -0.4957,  -1.6799,   7.6832,  18.8124,  -4.4849,  -5.2338,  12.4308,  15.8020,  -5.2306,  -6.0137,  12.6514,  15.5564, -10.9788,  -7.7449,  15.9215,  12.2624],\n",
       "         [  0.0000,   0.0000,   8.2590,  18.5191,  -0.3165,  -1.2434,   7.3536,  18.5492,  -4.1525,  -5.1216,  12.1533,  15.7269,  -4.9092,  -6.0789,  12.4866,  15.6268, -10.6106,  -7.5772,  15.4929,  13.1574],\n",
       "         [  0.0000,   0.0000,   8.6004,  18.0360,  -0.2791,  -0.4838,   7.2080,  18.6316,  -3.9265,  -5.0632,  12.0477,  16.0534,  -4.7970,  -5.8196,  12.5956,  15.5478, -10.3492,  -7.7678,  14.9846,  14.1377],\n",
       "         [  0.0000,   0.0000,   8.6936,  17.9998,  -0.5858,  -0.4414,   7.6321,  18.6367,  -3.8397,  -5.3894,  11.5230,  16.3626,  -5.0707,  -5.6752,  12.4308,  15.8020, -10.1498,  -7.8700,  14.6484,  14.4236],\n",
       "         [  0.0000,   0.0000,   8.7119,  18.0808,  -0.6525,  -0.7483,   8.2590,  18.5191,  -3.5067,  -5.5095,  11.2523,  16.9550,  -4.8049,  -5.8699,  12.1533,  15.7269,  -9.8335,  -7.9642,  14.6873,  14.3770]]),\n",
       " tensor([[ 7.4452, 12.8548],\n",
       "         [ 7.7211, 12.8112],\n",
       "         [ 7.9075, 12.2747],\n",
       "         [ 7.9320, 12.0309],\n",
       "         [ 8.0798, 11.1343],\n",
       "         [ 8.3218, 10.8547],\n",
       "         [ 8.6049, 11.0891],\n",
       "         [ 8.5967, 11.5417],\n",
       "         [ 8.3849, 11.6082],\n",
       "         [ 8.5714, 11.2286]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "ds_train, ds_test = random_split(dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "dl_train = DataLoader(ds_train, batch_size=256, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Best Model\n",
    "hidden_dims = [120, 40, 12, 4, 2]\n",
    "activaations = ['relu'] * (len(hidden_dims))# + ['softmax']\n",
    "in_dim = ds_train[0][0].shape[0]\n",
    "model = MLP(in_dim=in_dim, dims=hidden_dims, nonlins=activaations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_in_dim = 40\n",
    "block_dims = [10, 4, 10, 40]\n",
    "block_activations = ['relu'] * (len(block_dims))\n",
    "in_dim = 4 * len(dataset_config.input_frames)\n",
    "out_dim = 2*len(dataset_config.pred_frames)\n",
    "\n",
    "model = RMLP(in_dim=in_dim, block_in_dim=block_in_dim, block_dims=block_dims, block_nonlins=block_activations, n_blocks=4, out_dim=out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMLP(\n",
      "  (input): MLPLayer(\n",
      "    (mlp_layer): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=40, bias=True)\n",
      "      (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-3): 4 x MlpBlock(\n",
      "      (sequence): Sequential(\n",
      "        (0): MLPLayer(\n",
      "          (mlp_layer): Sequential(\n",
      "            (0): Linear(in_features=40, out_features=10, bias=True)\n",
      "            (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): MLPLayer(\n",
      "          (mlp_layer): Sequential(\n",
      "            (0): Linear(in_features=10, out_features=4, bias=True)\n",
      "            (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): MLPLayer(\n",
      "          (mlp_layer): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=10, bias=True)\n",
      "            (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (3): MLPLayer(\n",
      "          (mlp_layer): Sequential(\n",
      "            (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "            (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=40, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MLPTrainer(model, loss_fn, optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dl_train=dl_train, dl_test=dl_test, num_epochs=1000, checkpoints='logs/RecurrentMLP4.pt', print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_config = TimingConfig.load_json(\"/Users/guycohen/Desktop/Bio-Project/time_config.json\")\n",
    "\n",
    "log_path = \"/Users/guycohen/Desktop/Bio-Project/eval/bboxes2.csv\"\n",
    "\n",
    "\n",
    "pltr = Plotter(log_path, timing_config)\n",
    "data = pltr._data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(8), columns=['x', 'y'])\n",
    "df.iloc[0]  = [1, 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[0,-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.ag\n",
    "data.rolling(window=10, method='table').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40).reshape(8,5)[[2,3]].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.dropna(inplace=False, ignore_index=False, axis=0)\n",
    "mask = data.isna().any(axis=1)\n",
    "data['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that 0 is first at frames_for_pred\n",
    "def create_dataset(log_path: str, frames_for_pred=[0,-3,-15], pred_frame=7, save_path:str=None) -> Dataset:\n",
    "    data = pd.read_csv(log_path)\n",
    "    start_idx = abs(min(frames_for_pred)) + 1\n",
    "    X_mask = np.asanyarray(frames_for_pred)\n",
    "    y_mask = np.asanyarray([pred_frame])\n",
    "\n",
    "    data = Plotter.concat(data, Plotter.calc_centers(data, \"wrm\"))\n",
    "    \n",
    "    wrm_centers = data[['wrm_center_x', 'wrm_center_y']].to_numpy(dtype=np.float64)\n",
    "    wrm_boxes = data[['wrm_x', 'wrm_y', 'wrm_w', 'wrm_h']].to_numpy(dtype=np.float64)\n",
    "    \n",
    "    # Create columns for X and y\n",
    "    cols = ['wrm_x', 'wrm_y', 'wrm_w', 'wrm_h']\n",
    "    y_cols = ['wrm_center_x', 'wrm_center_y']\n",
    "    X_cols = []\n",
    "    for i in frames_for_pred:\n",
    "        X_cols += [col+str(i) for col in cols]\n",
    "    \n",
    "    # Create X and y\n",
    "    X = pd.DataFrame(index=data.index, columns=X_cols)\n",
    "    y = pd.DataFrame(index=data.index, columns=y_cols)\n",
    "    for i in range(start_idx, len(data)-pred_frame-1):\n",
    "        X.iloc[i] = wrm_boxes[i + X_mask].reshape(1, -1)\n",
    "        y.iloc[i] = wrm_centers[i + y_mask].reshape(1, -1)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    na_mask = np.ma.mask_or(X.isna().any(axis=1), y.isna().any(axis=1))\n",
    "    X = X.loc[~na_mask]\n",
    "    y = y.loc[~na_mask]\n",
    "    \n",
    "    X = X.to_numpy(dtype=np.float32, copy=True)\n",
    "    y = y.to_numpy(dtype=np.float32, copy=True)\n",
    "\n",
    "    # make X and y coordinates relative to the prediction frame\n",
    "    x_cord_mask = np.arange(X.shape[1]) % 4 == 0\n",
    "    y_cord_mask = np.arange(X.shape[1]) % 4 == 1\n",
    "    \n",
    "    x_cords = X[:, 0].reshape(-1, 1)\n",
    "    y_cords = X[:, 1].reshape(-1, 1)\n",
    "\n",
    "    y[:, [0]] -= x_cords\n",
    "    y[:, [1]] -= y_cords\n",
    "    X[:, x_cord_mask] -= x_cords#\n",
    "    X[:, y_cord_mask] -= y_cords#.reshape(-1, 1)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        np.save(save_path + \"dataset_X_3.npy\", X, allow_pickle=True)\n",
    "        np.save(save_path + \"dataset_y_3.npy\", y, allow_pickle=True)\n",
    "        # X.to_csv(save_path + \"dataset_X.csv\", index=False)\n",
    "        # y.to_csv(save_path + \"dataset_y.csv\", index=False)\n",
    "\n",
    "    return numpyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_path = \"/Users/guycohen/Desktop/Bio-Project/eval/bboxes2.csv\"\n",
    "log_path = f\"D:/Guy_Gilad/Exp1_GuyGilad/logs_yolo/bboxes.csv\"\n",
    "pred_frame=7\n",
    "frames_for_pred=[0,-3,-15,-18,-30]\n",
    "dataset = create_dataset(log_path, save_path=\"D:\\Guy_Gilad\\Bio-Proj\\evaluation\", frames_for_pred=frames_for_pred, pred_frame=pred_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ds[:]\n",
    "df = pd.DataFrame({\"dx\": y[:,0], \"dy\": y[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.5.4">
    
    
      
        <title>Training - Bio-Proj</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.80dcb947.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#4cae4f">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="green" data-md-color-accent="lightgreen">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-wtrackerneuraltraining" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Bio-Proj" class="md-header__button md-logo" aria-label="Bio-Proj" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Bio-Proj
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Training
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/giladfrid009/Bio-Proj" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Bio-Proj
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Bio-Proj" class="md-nav__button md-logo" aria-label="Bio-Proj" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Bio-Proj
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/giladfrid009/Bio-Proj" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Bio-Proj
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/Workflows/" class="md-nav__link">
        Workflows
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Wtracker
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Wtracker" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Wtracker
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_1" type="checkbox" id="__nav_3_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1">
          Dataset
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Dataset" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Dataset
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/bg_extractor/" class="md-nav__link">
        Bg Extractor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/box_calculator/" class="md-nav__link">
        Box Calculator
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/sample_extractor/" class="md-nav__link">
        Sample Extractor
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_2" type="checkbox" id="__nav_3_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2">
          Eval
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Eval" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Eval
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../eval/data_analyzer/" class="md-nav__link">
        Data Analyzer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../eval/error_calculator/" class="md-nav__link">
        Error Calculator
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../eval/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../eval/plotter/" class="md-nav__link">
        Plotter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../eval/vlc/" class="md-nav__link">
        Vlc
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_3" type="checkbox" id="__nav_3_1_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_3">
          Neural
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Neural" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_3">
          <span class="md-nav__icon md-icon"></span>
          Neural
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../config/" class="md-nav__link">
        Config
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dataset/" class="md-nav__link">
        Dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../mlp/" class="md-nav__link">
        Mlp
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../train_results/" class="md-nav__link">
        Train Results
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Training
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Training
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlptrainer" class="md-nav__link">
    MLPTrainer
  </a>
  
    <nav class="md-nav" aria-label="MLPTrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_hparam" class="md-nav__link">
    log_hparam
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_checkpoint" class="md-nav__link">
    save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_batch" class="md-nav__link">
    test_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_epoch" class="md-nav__link">
    test_epoch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_batch" class="md-nav__link">
    train_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_epoch" class="md-nav__link">
    train_epoch
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    Trainer
  </a>
  
    <nav class="md-nav" aria-label="Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes_1" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_hparam_1" class="md-nav__link">
    log_hparam
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_checkpoint_1" class="md-nav__link">
    save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_batch_1" class="md-nav__link">
    test_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_epoch_1" class="md-nav__link">
    test_epoch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_batch_1" class="md-nav__link">
    train_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_epoch_1" class="md-nav__link">
    train_epoch
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_4" type="checkbox" id="__nav_3_1_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_4">
          Sim
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sim" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_4">
          <span class="md-nav__icon md-icon"></span>
          Sim
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/config/" class="md-nav__link">
        Config
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/motor_controllers/" class="md-nav__link">
        Motor Controllers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/simulator/" class="md-nav__link">
        Simulator
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/view_controller/" class="md-nav__link">
        View Controller
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_4_6" type="checkbox" id="__nav_3_1_4_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_4_6">
          Sim Controllers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sim Controllers" data-md-level="4">
        <label class="md-nav__title" for="__nav_3_1_4_6">
          <span class="md-nav__icon md-icon"></span>
          Sim Controllers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/csv_controller/" class="md-nav__link">
        Csv Controller
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/logging_controller/" class="md-nav__link">
        Logging Controller
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/mlp_controllers/" class="md-nav__link">
        Mlp Controllers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/optimal_controller/" class="md-nav__link">
        Optimal Controller
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/polyfit_controller/" class="md-nav__link">
        Polyfit Controller
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../sim/sim_controllers/yolo_controller/" class="md-nav__link">
        Yolo Controller
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_5" type="checkbox" id="__nav_3_1_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_5">
          Utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Utils" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_5">
          <span class="md-nav__icon md-icon"></span>
          Utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/bbox_utils/" class="md-nav__link">
        Bbox Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/config_base/" class="md-nav__link">
        Config Base
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/frame_reader/" class="md-nav__link">
        Frame Reader
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/gui_utils/" class="md-nav__link">
        Gui Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/io_utils/" class="md-nav__link">
        Io Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/log_utils/" class="md-nav__link">
        Log Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/path_utils/" class="md-nav__link">
        Path Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/threading_utils/" class="md-nav__link">
        Threading Utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mlptrainer" class="md-nav__link">
    MLPTrainer
  </a>
  
    <nav class="md-nav" aria-label="MLPTrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_hparam" class="md-nav__link">
    log_hparam
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_checkpoint" class="md-nav__link">
    save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_batch" class="md-nav__link">
    test_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_epoch" class="md-nav__link">
    test_epoch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_batch" class="md-nav__link">
    train_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_epoch" class="md-nav__link">
    train_epoch
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    Trainer
  </a>
  
    <nav class="md-nav" aria-label="Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes_1" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fit_1" class="md-nav__link">
    fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_hparam_1" class="md-nav__link">
    log_hparam
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_checkpoint_1" class="md-nav__link">
    save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_batch_1" class="md-nav__link">
    test_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_epoch_1" class="md-nav__link">
    test_epoch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_batch_1" class="md-nav__link">
    train_batch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_epoch_1" class="md-nav__link">
    train_epoch
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/giladfrid009/Bio-Proj/edit/main/reference/wtracker/neural/training.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="module-wtrackerneuraltraining">Module wtracker.neural.training</h1>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">abc</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">import</span> <span class="nn">torch.nn.functional</span>

<span class="kn">import</span> <span class="nn">tqdm.auto</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="kn">from</span> <span class="nn">wtracker.neural.train_results</span> <span class="kn">import</span> <span class="n">FitResult</span><span class="p">,</span> <span class="n">BatchResult</span><span class="p">,</span> <span class="n">EpochResult</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    A class abstracting the various tasks of training models.</span>

<span class="sd">    Provides methods at multiple levels of granularity:</span>

<span class="sd">    - Multiple epochs (fit)</span>

<span class="sd">    - Single epoch (train_epoch/test_epoch)</span>

<span class="sd">    - Single batch (train_batch/test_batch)</span>

<span class="sd">    Args:</span>

<span class="sd">        model (nn.Module): The model to train.</span>

<span class="sd">        device (Optional[torch.device], optional): The device to run training on (CPU or GPU).</span>

<span class="sd">        log (bool, optional): Whether to log training progress with tensorboard.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>

        <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>

    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">log</span> <span class="k">else</span> <span class="n">SummaryWriter</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">},</span> <span class="p">{},</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)},</span> <span class="p">{},</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

            <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_batch_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_correct</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchResult</span><span class="p">:</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">loss</span>

        <span class="n">num_correct</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_correct</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">num_correct</span>

        <span class="k">return</span> <span class="n">BatchResult</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_correct</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_make_fit_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_losses</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FitResult</span><span class="p">:</span>

        <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">num_epochs</span>

        <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_losses</span><span class="p">]</span>

        <span class="n">train_acc</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_acc</span><span class="p">]</span>

        <span class="n">test_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_losses</span><span class="p">]</span>

        <span class="n">test_acc</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_acc</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">FitResult</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">),</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_losses</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">dl_train</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>

        <span class="n">dl_test</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>

        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>

        <span class="n">checkpoints</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>

        <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>

        <span class="n">print_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>

        <span class="o">**</span><span class="n">kw</span><span class="p">,</span>

    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FitResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Trains the model for multiple epochs with a given training set,</span>

<span class="sd">        and calculates validation loss over a given validation set.</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): Dataloader for the training set.</span>

<span class="sd">            dl_test (DataLoader): Dataloader for the test set.</span>

<span class="sd">            num_epochs (int): Number of epochs to train for.</span>

<span class="sd">            checkpoints (str, optional): Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</span>

<span class="sd">            early_stopping (int, optional): Whether to stop training early if there is no test loss improvement for this number of epochs.</span>

<span class="sd">            print_every (int, optional): Print progress every this number of epochs.</span>

<span class="sd">        Returns:</span>

<span class="sd">            FitResult: A FitResult object containing train and test losses per epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">actual_epoch_num</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># add graph to tensorboard</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl_train</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

            <span class="n">actual_epoch_num</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># pass this to train/test_epoch.</span>

            <span class="k">if</span> <span class="n">print_every</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>

                <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- EPOCH </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>

            <span class="n">train_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

            <span class="n">test_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_epoch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

            <span class="n">train_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

            <span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

            <span class="n">test_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

            <span class="n">test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

            <span class="c1"># log results to tensorboard</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/train&quot;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/test&quot;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/train&quot;</span><span class="p">,</span> <span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/test&quot;</span><span class="p">,</span> <span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="n">curr_val_loss</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">best_val_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">curr_val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>

                <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">curr_val_loss</span>

                <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">if</span> <span class="n">checkpoints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">curr_val_loss</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="n">epochs_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">early_stopping</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epochs_without_improvement</span> <span class="o">&gt;=</span> <span class="n">early_stopping</span><span class="p">:</span>

                    <span class="k">break</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_fit_result</span><span class="p">(</span><span class="n">actual_epoch_num</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Saves the model in it&#39;s current state to a file with the given name (treated</span>

<span class="sd">        as a relative path).</span>

<span class="sd">        Args:</span>

<span class="sd">            checkpoint_filename (str): File name or relative path to save to.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">checkpoint_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">checkpoint_filename</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_filename</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">*** Saved checkpoint </span><span class="si">{</span><span class="n">checkpoint_filename</span><span class="si">}</span><span class="s2"> :: val_loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dl_train</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Train once over a training set (single epoch).</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): DataLoader for the training set.</span>

<span class="sd">            kw: Keyword args supported by _foreach_batch.</span>

<span class="sd">        Returns:</span>

<span class="sd">            EpochResult: An EpochResult for the epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># set train mode</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_foreach_batch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dl_test</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Evaluate model once over a test set (single epoch).</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_test (DataLoader): DataLoader for the test set.</span>

<span class="sd">            kw: Keyword args supported by _foreach_batch.</span>

<span class="sd">        Returns:</span>

<span class="sd">            EpochResult: An EpochResult for the epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># set evaluation (test) mode</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_foreach_batch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_batch</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model, calculates loss,</span>

<span class="sd">        preforms back-propagation and updates weights.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>

    <span class="k">def</span> <span class="nf">test_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model and calculates loss.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>

    <span class="k">def</span> <span class="nf">_print</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simple wrapper around print to make it conditional&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>

    <span class="k">def</span> <span class="nf">_foreach_batch</span><span class="p">(</span>

        <span class="n">dl</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>

        <span class="n">forward_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">BatchResult</span><span class="p">],</span>

        <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>

        <span class="n">max_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>

    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Evaluates the given forward-function on batches from the given</span>

<span class="sd">        dataloader, and prints progress along the way.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dl</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>

        <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dl</span><span class="o">.</span><span class="n">batch_sampler</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">if</span> <span class="n">max_batches</span> <span class="o">&lt;</span> <span class="n">num_batches</span><span class="p">:</span>

                <span class="n">num_batches</span> <span class="o">=</span> <span class="n">max_batches</span>

                <span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_batches</span> <span class="o">*</span> <span class="n">dl</span><span class="o">.</span><span class="n">batch_size</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>

            <span class="n">pbar_fn</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">auto</span><span class="o">.</span><span class="n">tqdm</span>

            <span class="n">pbar_file</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">pbar_fn</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span>

            <span class="n">pbar_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">devnull</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>

        <span class="n">pbar_name</span> <span class="o">=</span> <span class="n">forward_fn</span><span class="o">.</span><span class="vm">__name__</span>

        <span class="k">with</span> <span class="n">pbar_fn</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="n">pbar_name</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">pbar_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>

            <span class="n">dl_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>

                <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dl_iter</span><span class="p">)</span>

                <span class="n">batch_res</span> <span class="o">=</span> <span class="n">forward_fn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

                <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pbar_name</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">batch_res</span><span class="o">.</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

                <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_res</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

                <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">batch_res</span><span class="o">.</span><span class="n">num_correct</span>

            <span class="n">avg_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_batches</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">num_correct</span> <span class="o">/</span> <span class="n">num_samples</span>

            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pbar_name</span><span class="si">}</span><span class="s2"> &quot;</span> <span class="sa">f</span><span class="s2">&quot;(Avg. Loss </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, &quot;</span> <span class="sa">f</span><span class="s2">&quot;Accuracy </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">verbose</span><span class="p">:</span>

            <span class="n">pbar_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">EpochResult</span><span class="p">(</span><span class="n">losses</span><span class="o">=</span><span class="n">losses</span><span class="p">,</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">log_hparam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hparam_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">metric_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span> <span class="n">run_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;hparams&quot;</span><span class="p">):</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">,</span> <span class="n">metric_dict</span><span class="p">,</span> <span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MLPTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    The `MLPTrainer` class is responsible for training and testing a multi-layer perceptron (MLP) models.</span>

<span class="sd">    Args:</span>

<span class="sd">        model (nn.Module): The MLP model to be trained.</span>

<span class="sd">        loss_fn (nn.Module): The loss function used for training.</span>

<span class="sd">        optimizer (Optimizer): The optimizer used for updating the model&#39;s parameters.</span>

<span class="sd">        device (Optional[torch.device], optional): The device on which the model and data should be loaded.</span>

<span class="sd">        log (bool, optional): Whether to log training progress with tensorboard.</span>

<span class="sd">    Attributes:</span>

<span class="sd">        loss_fn (nn.Module): The loss function used for training.</span>

<span class="sd">        optimizer (Optimizer): The optimizer used for updating the model&#39;s parameters.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span>

        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>

        <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>

    <span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">:</span> <span class="n">loss_fn</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">},</span> <span class="p">{},</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">},</span> <span class="p">{},</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

            <span class="n">optimizer_params</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

                <span class="n">optimizer_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

            <span class="n">optimizer_params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">})</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">optimizer_params</span><span class="p">,</span> <span class="p">{},</span> <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchResult</span><span class="p">:</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">num_correct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">preds</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">num_correct</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchResult</span><span class="p">:</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">num_correct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">preds</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">num_correct</span><span class="p">)</span>
</code></pre></div>

</details>
<h2 id="classes">Classes</h2>
<h3 id="mlptrainer">MLPTrainer</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MLPTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>The <code>MLPTrainer</code> class is responsible for training and testing a multi-layer perceptron (MLP) models.</p>
<h4 id="attributes">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>model</td>
<td>nn.Module</td>
<td>The MLP model to be trained.</td>
<td>None</td>
</tr>
<tr>
<td>loss_fn</td>
<td>nn.Module</td>
<td>The loss function used for training.</td>
<td>None</td>
</tr>
<tr>
<td>optimizer</td>
<td>Optimizer</td>
<td>The optimizer used for updating the model's parameters.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>Optional[torch.device]</td>
<td>The device on which the model and data should be loaded.</td>
<td>None</td>
</tr>
<tr>
<td>log</td>
<td>bool</td>
<td>Whether to log training progress with tensorboard.</td>
<td>None</td>
</tr>
<tr>
<td>loss_fn</td>
<td>nn.Module</td>
<td>The loss function used for training.</td>
<td>None</td>
</tr>
<tr>
<td>optimizer</td>
<td>Optimizer</td>
<td>The optimizer used for updating the model's parameters.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="n">MLPTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    The `MLPTrainer` class is responsible for training and testing a multi-layer perceptron (MLP) models.</span>

<span class="sd">    Args:</span>

<span class="sd">        model (nn.Module): The MLP model to be trained.</span>

<span class="sd">        loss_fn (nn.Module): The loss function used for training.</span>

<span class="sd">        optimizer (Optimizer): The optimizer used for updating the model&#39;s parameters.</span>

<span class="sd">        device (Optional[torch.device], optional): The device on which the model and data should be loaded.</span>

<span class="sd">        log (bool, optional): Whether to log training progress with tensorboard.</span>

<span class="sd">    Attributes:</span>

<span class="sd">        loss_fn (nn.Module): The loss function used for training.</span>

<span class="sd">        optimizer (Optimizer): The optimizer used for updating the model&#39;s parameters.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">model</span><span class="p">:</span><span class="w"> </span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

<span class="w">        </span><span class="n">loss_fn</span><span class="p">:</span><span class="w"> </span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

<span class="w">        </span><span class="n">optimizer</span><span class="p">:</span><span class="w"> </span><span class="n">Optimizer</span><span class="p">,</span>

<span class="w">        </span><span class="n">device</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="nb">log</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">bool</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="n">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="nb">log</span><span class="o">=</span><span class="nb">log</span><span class="p">)</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss_fn</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optimizer</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">:</span><span class="w"> </span><span class="n">loss_fn</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">},</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">},</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="n">optimizer_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{}</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

<span class="w">                </span><span class="n">optimizer_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">str</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

<span class="w">            </span><span class="n">optimizer_params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">})</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">optimizer_params</span><span class="p">,</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

<span class="w">            </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span><span class="w"> </span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="w">        </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">preds</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">num_correct</span><span class="p">)</span>

<span class="w">    </span><span class="err">@</span><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

<span class="w">            </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">        </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">preds</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">num_correct</span><span class="p">)</span>
</code></pre></div>

</details>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>wtracker.neural.training.Trainer</li>
<li>abc.ABC</li>
</ul>
<h4 id="methods">Methods</h4>
<h4 id="fit">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_train</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">dl_test</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">checkpoints</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">print_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">FitResult</span>
</code></pre></div>

<p>Trains the model for multiple epochs with a given training set,</p>
<p>and calculates validation loss over a given validation set.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_train</td>
<td>DataLoader</td>
<td>Dataloader for the training set.</td>
<td>None</td>
</tr>
<tr>
<td>dl_test</td>
<td>DataLoader</td>
<td>Dataloader for the test set.</td>
<td>None</td>
</tr>
<tr>
<td>num_epochs</td>
<td>int</td>
<td>Number of epochs to train for.</td>
<td>None</td>
</tr>
<tr>
<td>checkpoints</td>
<td>str</td>
<td>Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</td>
<td>None</td>
</tr>
<tr>
<td>early_stopping</td>
<td>int</td>
<td>Whether to stop training early if there is no test loss improvement for this number of epochs.</td>
<td>None</td>
</tr>
<tr>
<td>print_every</td>
<td>int</td>
<td>Print progress every this number of epochs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>FitResult</td>
<td>A FitResult object containing train and test losses per epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_train</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_test</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="p">,</span>

<span class="w">        </span><span class="n">checkpoints</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">early_stopping</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">print_every</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kw</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">FitResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Trains the model for multiple epochs with a given training set,</span>

<span class="sd">        and calculates validation loss over a given validation set.</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): Dataloader for the training set.</span>

<span class="sd">            dl_test (DataLoader): Dataloader for the test set.</span>

<span class="sd">            num_epochs (int): Number of epochs to train for.</span>

<span class="sd">            checkpoints (str, optional): Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</span>

<span class="sd">            early_stopping (int, optional): Whether to stop training early if there is no test loss improvement for this number of epochs.</span>

<span class="sd">            print_every (int, optional): Print progress every this number of epochs.</span>

<span class="sd">        Returns:</span>

<span class="sd">            FitResult: A FitResult object containing train and test losses per epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">        </span><span class="c1"># add graph to tensorboard</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">next</span><span class="p">(</span><span class="n">iter</span><span class="p">(</span><span class="n">dl_train</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

<span class="w">            </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">            </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w">  </span><span class="c1"># pass this to train/test_epoch.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">epoch</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">num_epochs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">):</span>

<span class="w">                </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;--- EPOCH {epoch+1}/{num_epochs} ---&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">test_epoch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># log results to tensorboard</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">            </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">best_val_loss</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">best_val_loss</span><span class="p">:</span>

<span class="w">                </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr_val_loss</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">checkpoints</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">early_stopping</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">early_stopping</span><span class="p">:</span>

<span class="w">                    </span><span class="k">break</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_make_fit_result</span><span class="p">(</span><span class="n">actual_epoch_num</span><span class="p">,</span><span class="w"> </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="log_hparam">log_hparam</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">log_hparam</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hparam_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">metric_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">run_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;hparams&#39;</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def log_hparam(self, hparam_dict: dict[str, Any], metric_dict: dict[str, Any] = {}, run_name: str = &quot;hparams&quot;):

        if self.logger is not None:

            self.logger.add_hparams(hparam_dict, metric_dict, run_name=run_name)
</code></pre></div>

</details>
<h4 id="save_checkpoint">save_checkpoint</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

<p>Saves the model in it's current state to a file with the given name (treated</p>
<p>as a relative path).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>checkpoint_filename</td>
<td>str</td>
<td>File name or relative path to save to.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">checkpoint_filename</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">,</span><span class="w"> </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">float</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Saves the model in it&#39;s current state to a file with the given name (treated</span>

<span class="ss">        as a relative path).</span>

<span class="ss">        Args:</span>

<span class="ss">            checkpoint_filename (str): File name or relative path to save to.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">            </span><span class="n">checkpoint_filename</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="ss">&quot;{self.logger.log_dir}/{checkpoint_filename}&quot;</span>

<span class="w">        </span><span class="n">torch</span><span class="p">.</span><span class="k">save</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">checkpoint_filename</span><span class="p">)</span>

<span class="w">        </span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;\n*** Saved checkpoint {checkpoint_filename} :: val_loss={loss:.3f}&quot;</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_batch">test_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">BatchResult</span>
</code></pre></div>

<p>Runs a single batch forward through the model and calculates loss.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A single batch of data from a data loader (might<br>be a tuple of data and labels or anything else depending on<br>the underlying dataset).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchResult</td>
<td>A BatchResult containing the value of the loss function and<br>the number of correctly classified samples in the batch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nv">@torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nl">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">device</span><span class="p">:</span>

<span class="w">            </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">.</span><span class="k">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">.</span><span class="k">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">        </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">preds</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">).</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">num_correct</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_epoch">test_epoch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_test</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">EpochResult</span>
</code></pre></div>

<p>Evaluate model once over a test set (single epoch).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_test</td>
<td>DataLoader</td>
<td>DataLoader for the test set.</td>
<td>None</td>
</tr>
<tr>
<td>kw</td>
<td>None</td>
<td>Keyword args supported by _foreach_batch.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>EpochResult</td>
<td>An EpochResult for the epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def test_epoch(self, dl_test: DataLoader, **kw) -&gt; EpochResult:

        &quot;&quot;&quot;

        Evaluate model once over a test set (single epoch).

        Args:

            dl_test (DataLoader): DataLoader for the test set.

            kw: Keyword args supported by _foreach_batch.

        Returns:

            EpochResult: An EpochResult for the epoch.

        &quot;&quot;&quot;

        self.model.train(False)  # set evaluation (test) mode

        return self._foreach_batch(dl_test, self.test_batch, **kw)
</code></pre></div>

</details>
<h4 id="train_batch">train_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">BatchResult</span>
</code></pre></div>

<p>Runs a single batch forward through the model, calculates loss,</p>
<p>preforms back-propagation and updates weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A single batch of data from a data loader (might<br>be a tuple of data and labels or anything else depending on<br>the underlying dataset).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchResult</td>
<td>A BatchResult containing the value of the loss function and<br>the number of correctly classified samples in the batch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_batch</span><span class="p">(</span><span class="kr">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="o">:</span>

<span class="w">        </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span>

<span class="w">        </span><span class="nf">if</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">device</span><span class="o">:</span>

<span class="w">            </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="kr">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="kr">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">        </span><span class="kr">self</span><span class="p">.</span><span class="n">model</span><span class="o">:</span><span class="w"> </span><span class="n">nn</span><span class="p">.</span><span class="kr">Module</span>

<span class="w">        </span><span class="kr">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="w">        </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="w">        </span><span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

<span class="w">        </span><span class="kr">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">preds</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">).</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span>

<span class="w">        </span><span class="kr">return</span><span class="w"> </span><span class="kr">self</span><span class="p">.</span><span class="n">_make_batch_result</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">num_correct</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_epoch">train_epoch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_train</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">EpochResult</span>
</code></pre></div>

<p>Train once over a training set (single epoch).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_train</td>
<td>DataLoader</td>
<td>DataLoader for the training set.</td>
<td>None</td>
</tr>
<tr>
<td>kw</td>
<td>None</td>
<td>Keyword args supported by _foreach_batch.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>EpochResult</td>
<td>An EpochResult for the epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def train_epoch(self, dl_train: DataLoader, **kw) -&gt; EpochResult:

        &quot;&quot;&quot;

        Train once over a training set (single epoch).

        Args:

            dl_train (DataLoader): DataLoader for the training set.

            kw: Keyword args supported by _foreach_batch.

        Returns:

            EpochResult: An EpochResult for the epoch.

        &quot;&quot;&quot;

        self.model.train(True)  # set train mode

        return self._foreach_batch(dl_train, self.train_batch, **kw)
</code></pre></div>

</details>
<h3 id="trainer">Trainer</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>A class abstracting the various tasks of training models.</p>
<p>Provides methods at multiple levels of granularity:
- Multiple epochs (fit)
- Single epoch (train_epoch/test_epoch)
- Single batch (train_batch/test_batch)</p>
<h4 id="attributes_1">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>model</td>
<td>nn.Module</td>
<td>The model to train.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>Optional[torch.device]</td>
<td>The device to run training on (CPU or GPU).</td>
<td>None</td>
</tr>
<tr>
<td>log</td>
<td>bool</td>
<td>Whether to log training progress with tensorboard.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="n">Trainer</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    A class abstracting the various tasks of training models.</span>

<span class="sd">    Provides methods at multiple levels of granularity:</span>

<span class="sd">    - Multiple epochs (fit)</span>

<span class="sd">    - Single epoch (train_epoch/test_epoch)</span>

<span class="sd">    - Single batch (train_batch/test_batch)</span>

<span class="sd">    Args:</span>

<span class="sd">        model (nn.Module): The model to train.</span>

<span class="sd">        device (Optional[torch.device], optional): The device to run training on (CPU or GPU).</span>

<span class="sd">        log (bool, optional): Whether to log training progress with tensorboard.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">__init__</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">model</span><span class="p">:</span><span class="w"> </span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>

<span class="w">        </span><span class="n">device</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="nb">log</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">bool</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="p">,</span>

<span class="w">    </span><span class="p">):</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">device</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="nb">log</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">SummaryWriter</span><span class="p">()</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">},</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">({</span><span class="s2">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)},</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;hparams&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>

<span class="w">            </span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_make_batch_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">num_correct</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">loss</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_correct</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">num_correct</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">num_correct</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">(</span><span class="nb nb-Type">float</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="p">(</span><span class="n">num_correct</span><span class="p">))</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_make_fit_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">num_epochs</span><span class="p">,</span><span class="w"> </span><span class="n">train_losses</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_losses</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">FitResult</span><span class="p">:</span>

<span class="w">        </span><span class="n">num_epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_epochs</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">num_epochs</span>

<span class="w">        </span><span class="n">train_losses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">train_losses</span><span class="p">]</span>

<span class="w">        </span><span class="n">train_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">train_acc</span><span class="p">]</span>

<span class="w">        </span><span class="n">test_losses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">test_losses</span><span class="p">]</span>

<span class="w">        </span><span class="n">test_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">test_acc</span><span class="p">]</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">FitResult</span><span class="p">(</span><span class="nb nb-Type">int</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">),</span><span class="w"> </span><span class="n">train_losses</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_losses</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_train</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_test</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="p">,</span>

<span class="w">        </span><span class="n">checkpoints</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">early_stopping</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">print_every</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kw</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">FitResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Trains the model for multiple epochs with a given training set,</span>

<span class="sd">        and calculates validation loss over a given validation set.</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): Dataloader for the training set.</span>

<span class="sd">            dl_test (DataLoader): Dataloader for the test set.</span>

<span class="sd">            num_epochs (int): Number of epochs to train for.</span>

<span class="sd">            checkpoints (str, optional): Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</span>

<span class="sd">            early_stopping (int, optional): Whether to stop training early if there is no test loss improvement for this number of epochs.</span>

<span class="sd">            print_every (int, optional): Print progress every this number of epochs.</span>

<span class="sd">        Returns:</span>

<span class="sd">            FitResult: A FitResult object containing train and test losses per epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">        </span><span class="c1"># add graph to tensorboard</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">next</span><span class="p">(</span><span class="n">iter</span><span class="p">(</span><span class="n">dl_train</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

<span class="w">            </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">            </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w">  </span><span class="c1"># pass this to train/test_epoch.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">epoch</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">num_epochs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">):</span>

<span class="w">                </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;--- EPOCH {epoch+1}/{num_epochs} ---&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">test_epoch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># log results to tensorboard</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">            </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">best_val_loss</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">best_val_loss</span><span class="p">:</span>

<span class="w">                </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr_val_loss</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">checkpoints</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">early_stopping</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">early_stopping</span><span class="p">:</span>

<span class="w">                    </span><span class="k">break</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_make_fit_result</span><span class="p">(</span><span class="n">actual_epoch_num</span><span class="p">,</span><span class="w"> </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">checkpoint_filename</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="p">[</span><span class="nb nb-Type">float</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Saves the model in it&#39;s current state to a file with the given name (treated</span>

<span class="sd">        as a relative path).</span>

<span class="sd">        Args:</span>

<span class="sd">            checkpoint_filename (str): File name or relative path to save to.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="n">checkpoint_filename</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="s2">&quot;{self.logger.log_dir}/{checkpoint_filename}&quot;</span>

<span class="w">        </span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">checkpoint_filename</span><span class="p">)</span>

<span class="w">        </span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">*** Saved checkpoint {checkpoint_filename} :: val_loss={loss:.3f}&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">dl_train</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Train once over a training set (single epoch).</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): DataLoader for the training set.</span>

<span class="sd">            kw: Keyword args supported by _foreach_batch.</span>

<span class="sd">        Returns:</span>

<span class="sd">            EpochResult: An EpochResult for the epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">True</span><span class="p">)</span><span class="w">  </span><span class="c1"># set train mode</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_foreach_batch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_batch</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">dl_test</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Evaluate model once over a test set (single epoch).</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_test (DataLoader): DataLoader for the test set.</span>

<span class="sd">            kw: Keyword args supported by _foreach_batch.</span>

<span class="sd">        Returns:</span>

<span class="sd">            EpochResult: An EpochResult for the epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">False</span><span class="p">)</span><span class="w">  </span><span class="c1"># set evaluation (test) mode</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_foreach_batch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">test_batch</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">    </span><span class="err">@</span><span class="n">abc</span><span class="o">.</span><span class="n">abstractmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model, calculates loss,</span>

<span class="sd">        preforms back-propagation and updates weights.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">()</span>

<span class="w">    </span><span class="err">@</span><span class="n">abc</span><span class="o">.</span><span class="n">abstractmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model and calculates loss.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">()</span>

<span class="w">    </span><span class="err">@</span><span class="n">staticmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_print</span><span class="p">(</span><span class="n">message</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">True</span><span class="p">):</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simple wrapper around print to make it conditional&quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">verbose</span><span class="p">:</span>

<span class="w">            </span><span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

<span class="w">    </span><span class="err">@</span><span class="n">staticmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">_foreach_batch</span><span class="p">(</span>

<span class="w">        </span><span class="n">dl</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">forward_fn</span><span class="p">:</span><span class="w"> </span><span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">],</span>

<span class="w">        </span><span class="n">verbose</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

<span class="w">        </span><span class="n">max_batches</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">EpochResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Evaluates the given forward-function on batches from the given</span>

<span class="sd">        dataloader, and prints progress along the way.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">losses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="n">num_correct</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">num_samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">dl</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>

<span class="w">        </span><span class="n">num_batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">len</span><span class="p">(</span><span class="n">dl</span><span class="o">.</span><span class="n">batch_sampler</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">max_batches</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">max_batches</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_batches</span><span class="p">:</span>

<span class="w">                </span><span class="n">num_batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max_batches</span>

<span class="w">                </span><span class="n">num_samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">num_batches</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dl</span><span class="o">.</span><span class="n">batch_size</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">verbose</span><span class="p">:</span>

<span class="w">            </span><span class="n">pbar_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tqdm</span><span class="o">.</span><span class="n">auto</span><span class="o">.</span><span class="n">tqdm</span>

<span class="w">            </span><span class="n">pbar_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="w">        </span><span class="k">else</span><span class="p">:</span>

<span class="w">            </span><span class="n">pbar_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span>

<span class="w">            </span><span class="n">pbar_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">devnull</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;w&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="n">pbar_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">forward_fn</span><span class="o">.</span><span class="n">__name__</span>

<span class="w">        </span><span class="n">with</span><span class="w"> </span><span class="n">pbar_fn</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="n">pbar_name</span><span class="p">,</span><span class="w"> </span><span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span><span class="w"> </span><span class="n">file</span><span class="o">=</span><span class="n">pbar_file</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">pbar</span><span class="p">:</span>

<span class="w">            </span><span class="n">dl_iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">batch_idx</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>

<span class="w">                </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">next</span><span class="p">(</span><span class="n">dl_iter</span><span class="p">)</span>

<span class="w">                </span><span class="n">batch_res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">forward_fn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="w">                </span><span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;{pbar_name} ({batch_res.loss:.3f})&quot;</span><span class="p">)</span>

<span class="w">                </span><span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

<span class="w">                </span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_res</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

<span class="w">                </span><span class="n">num_correct</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">batch_res</span><span class="o">.</span><span class="n">num_correct</span>

<span class="w">            </span><span class="n">avg_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_batches</span>

<span class="w">            </span><span class="n">accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">100.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">num_correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_samples</span>

<span class="w">            </span><span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;{pbar_name} &quot;</span><span class="w"> </span><span class="n">f</span><span class="s2">&quot;(Avg. Loss {avg_loss:.3f}, &quot;</span><span class="w"> </span><span class="n">f</span><span class="s2">&quot;Accuracy {accuracy:.2f}%)&quot;</span><span class="p">)</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">verbose</span><span class="p">:</span>

<span class="w">            </span><span class="n">pbar_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">EpochResult</span><span class="p">(</span><span class="n">losses</span><span class="o">=</span><span class="n">losses</span><span class="p">,</span><span class="w"> </span><span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">log_hparam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">hparam_dict</span><span class="p">:</span><span class="w"> </span><span class="n">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">Any</span><span class="p">],</span><span class="w"> </span><span class="n">metric_dict</span><span class="p">:</span><span class="w"> </span><span class="n">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="w"> </span><span class="n">Any</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{},</span><span class="w"> </span><span class="n">run_name</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;hparams&quot;</span><span class="p">):</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_hparams</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">,</span><span class="w"> </span><span class="n">metric_dict</span><span class="p">,</span><span class="w"> </span><span class="n">run_name</span><span class="o">=</span><span class="n">run_name</span><span class="p">)</span>
</code></pre></div>

</details>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>abc.ABC</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>wtracker.neural.training.MLPTrainer</li>
</ul>
<h4 id="methods_1">Methods</h4>
<h4 id="fit_1">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_train</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">dl_test</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">checkpoints</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">print_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">FitResult</span>
</code></pre></div>

<p>Trains the model for multiple epochs with a given training set,</p>
<p>and calculates validation loss over a given validation set.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_train</td>
<td>DataLoader</td>
<td>Dataloader for the training set.</td>
<td>None</td>
</tr>
<tr>
<td>dl_test</td>
<td>DataLoader</td>
<td>Dataloader for the test set.</td>
<td>None</td>
</tr>
<tr>
<td>num_epochs</td>
<td>int</td>
<td>Number of epochs to train for.</td>
<td>None</td>
</tr>
<tr>
<td>checkpoints</td>
<td>str</td>
<td>Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</td>
<td>None</td>
</tr>
<tr>
<td>early_stopping</td>
<td>int</td>
<td>Whether to stop training early if there is no test loss improvement for this number of epochs.</td>
<td>None</td>
</tr>
<tr>
<td>print_every</td>
<td>int</td>
<td>Print progress every this number of epochs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>FitResult</td>
<td>A FitResult object containing train and test losses per epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span>

<span class="w">        </span><span class="bp">self</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_train</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">dl_test</span><span class="p">:</span><span class="w"> </span><span class="n">DataLoader</span><span class="p">,</span>

<span class="w">        </span><span class="n">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="p">,</span>

<span class="w">        </span><span class="n">checkpoints</span><span class="p">:</span><span class="w"> </span><span class="nb">str</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">early_stopping</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span><span class="p">,</span>

<span class="w">        </span><span class="n">print_every</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>

<span class="w">        </span><span class="o">**</span><span class="n">kw</span><span class="p">,</span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">FitResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Trains the model for multiple epochs with a given training set,</span>

<span class="sd">        and calculates validation loss over a given validation set.</span>

<span class="sd">        Args:</span>

<span class="sd">            dl_train (DataLoader): Dataloader for the training set.</span>

<span class="sd">            dl_test (DataLoader): Dataloader for the test set.</span>

<span class="sd">            num_epochs (int): Number of epochs to train for.</span>

<span class="sd">            checkpoints (str, optional): Whether to save model to file every time the test set accuracy improves. Should be a string containing a filename without extension.</span>

<span class="sd">            early_stopping (int, optional): Whether to stop training early if there is no test loss improvement for this number of epochs.</span>

<span class="sd">            print_every (int, optional): Print progress every this number of epochs.</span>

<span class="sd">        Returns:</span>

<span class="sd">            FitResult: A FitResult object containing train and test losses per epoch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">        </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[],</span><span class="w"> </span><span class="p">[]</span>

<span class="w">        </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">None</span>

<span class="w">        </span><span class="c1"># add graph to tensorboard</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">next</span><span class="p">(</span><span class="n">iter</span><span class="p">(</span><span class="n">dl_train</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

<span class="w">            </span><span class="n">actual_epoch_num</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">            </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">False</span><span class="w">  </span><span class="c1"># pass this to train/test_epoch.</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="p">(</span><span class="n">epoch</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">print_every</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">num_epochs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">):</span>

<span class="w">                </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">True</span>

<span class="w">            </span><span class="bp">self</span><span class="o">.</span><span class="n">_print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;--- EPOCH {epoch+1}/{num_epochs} ---&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">test_epoch</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_loss</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

<span class="w">            </span><span class="n">test_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">)</span>

<span class="w">            </span><span class="c1"># log results to tensorboard</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">train_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;loss/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">train_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;accuracy/test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">test_result</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">                </span><span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">epoch</span><span class="p">)</span>

<span class="w">            </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">test_result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">best_val_loss</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">best_val_loss</span><span class="p">:</span>

<span class="w">                </span><span class="n">best_val_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">curr_val_loss</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">checkpoints</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="p">:</span>

<span class="w">                    </span><span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span><span class="w"> </span><span class="n">curr_val_loss</span><span class="p">)</span>

<span class="w">            </span><span class="k">else</span><span class="p">:</span>

<span class="w">                </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">1</span>

<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">early_stopping</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">None</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">epochs_without_improvement</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">early_stopping</span><span class="p">:</span>

<span class="w">                    </span><span class="k">break</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_make_fit_result</span><span class="p">(</span><span class="n">actual_epoch_num</span><span class="p">,</span><span class="w"> </span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">train_acc</span><span class="p">,</span><span class="w"> </span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">test_acc</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="log_hparam_1">log_hparam</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">log_hparam</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hparam_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">metric_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
    <span class="n">run_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;hparams&#39;</span>
<span class="p">)</span>
</code></pre></div>

<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def log_hparam(self, hparam_dict: dict[str, Any], metric_dict: dict[str, Any] = {}, run_name: str = &quot;hparams&quot;):

        if self.logger is not None:

            self.logger.add_hparams(hparam_dict, metric_dict, run_name=run_name)
</code></pre></div>

</details>
<h4 id="save_checkpoint_1">save_checkpoint</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint_filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

<p>Saves the model in it's current state to a file with the given name (treated</p>
<p>as a relative path).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>checkpoint_filename</td>
<td>str</td>
<td>File name or relative path to save to.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="nl">checkpoint_filename</span><span class="p">:</span><span class="w"> </span><span class="nf">str</span><span class="p">,</span><span class="w"> </span><span class="nl">loss</span><span class="p">:</span><span class="w"> </span><span class="n">Optional</span><span class="o">[</span><span class="n">float</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        Saves the model in it&#39;s current state to a file with the given name (treated</span>

<span class="ss">        as a relative path).</span>

<span class="ss">        Args:</span>

<span class="ss">            checkpoint_filename (str): File name or relative path to save to.</span>

<span class="ss">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="err">:</span>

<span class="w">            </span><span class="n">checkpoint_filename</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f</span><span class="ss">&quot;{self.logger.log_dir}/{checkpoint_filename}&quot;</span>

<span class="w">        </span><span class="n">torch</span><span class="p">.</span><span class="k">save</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">checkpoint_filename</span><span class="p">)</span>

<span class="w">        </span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="ss">&quot;\n*** Saved checkpoint {checkpoint_filename} :: val_loss={loss:.3f}&quot;</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_batch_1">test_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">BatchResult</span>
</code></pre></div>

<p>Runs a single batch forward through the model and calculates loss.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A single batch of data from a data loader (might<br>be a tuple of data and labels or anything else depending on<br>the underlying dataset).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchResult</td>
<td>A BatchResult containing the value of the loss function and<br>the number of correctly classified samples in the batch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">abc</span><span class="o">.</span><span class="n">abstractmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">test_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model and calculates loss.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="test_epoch_1">test_epoch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_epoch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_test</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">EpochResult</span>
</code></pre></div>

<p>Evaluate model once over a test set (single epoch).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_test</td>
<td>DataLoader</td>
<td>DataLoader for the test set.</td>
<td>None</td>
</tr>
<tr>
<td>kw</td>
<td>None</td>
<td>Keyword args supported by _foreach_batch.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>EpochResult</td>
<td>An EpochResult for the epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def test_epoch(self, dl_test: DataLoader, **kw) -&gt; EpochResult:

        &quot;&quot;&quot;

        Evaluate model once over a test set (single epoch).

        Args:

            dl_test (DataLoader): DataLoader for the test set.

            kw: Keyword args supported by _foreach_batch.

        Returns:

            EpochResult: An EpochResult for the epoch.

        &quot;&quot;&quot;

        self.model.train(False)  # set evaluation (test) mode

        return self._foreach_batch(dl_test, self.test_batch, **kw)
</code></pre></div>

</details>
<h4 id="train_batch_1">train_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">BatchResult</span>
</code></pre></div>

<p>Runs a single batch forward through the model, calculates loss,</p>
<p>preforms back-propagation and updates weights.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A single batch of data from a data loader (might<br>be a tuple of data and labels or anything else depending on<br>the underlying dataset).</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchResult</td>
<td>A BatchResult containing the value of the loss function and<br>the number of correctly classified samples in the batch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="err">@</span><span class="n">abc</span><span class="o">.</span><span class="n">abstractmethod</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">batch</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">BatchResult</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Runs a single batch forward through the model, calculates loss,</span>

<span class="sd">        preforms back-propagation and updates weights.</span>

<span class="sd">        Args:</span>

<span class="sd">            batch: A single batch of data from a data loader (might</span>

<span class="sd">                be a tuple of data and labels or anything else depending on</span>

<span class="sd">                the underlying dataset).</span>

<span class="sd">        Returns:</span>

<span class="sd">            BatchResult: A BatchResult containing the value of the loss function and</span>

<span class="sd">                the number of correctly classified samples in the batch.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">NotImplementedError</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="train_epoch_1">train_epoch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dl_train</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kw</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">wtracker</span><span class="o">.</span><span class="n">neural</span><span class="o">.</span><span class="n">train_results</span><span class="o">.</span><span class="n">EpochResult</span>
</code></pre></div>

<p>Train once over a training set (single epoch).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>dl_train</td>
<td>DataLoader</td>
<td>DataLoader for the training set.</td>
<td>None</td>
</tr>
<tr>
<td>kw</td>
<td>None</td>
<td>Keyword args supported by _foreach_batch.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>EpochResult</td>
<td>An EpochResult for the epoch.</td>
</tr>
</tbody>
</table>
<details class="example">
<summary>View Source</summary>
<div class="codehilite"><pre><span></span><code>    def train_epoch(self, dl_train: DataLoader, **kw) -&gt; EpochResult:

        &quot;&quot;&quot;

        Train once over a training set (single epoch).

        Args:

            dl_train (DataLoader): DataLoader for the training set.

            kw: Keyword args supported by _foreach_batch.

        Returns:

            EpochResult: An EpochResult for the epoch.

        &quot;&quot;&quot;

        self.model.train(True)  # set train mode

        return self._foreach_batch(dl_train, self.train_batch, **kw)
</code></pre></div>

</details>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        
<footer class="md-footer">
    
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../train_results/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Train Results" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Previous
                </span>
                Train Results
              </div>
            </div>
          </a>
        
        
          
          <a href="../../sim/config/" class="md-footer__link md-footer__link--next" aria-label="Next: Config" rel="next">
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Next
                </span>
                Config
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
            
            Powered by
            <a href="http://timothycrosley.github.io/portray">portray.</a>
            You too can
            <a href="http://timothycrosley.github.io/portray">
              portray</a>
            your Python project well using automatic documentation.
          </div>
        
      </div>
    </div>
  </footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.078830c0.min.js"></script>
      
    
  </body>
</html>